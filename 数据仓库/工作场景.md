# 数仓分析
- ods层：操作数据层/源数据层
  - 性能数据（流量），干扰数据，感知数据，告警数据，投诉数据，
  - 时间粒度（15min,小时粒度，天粒度），天20w,小时500w,15min2000W，一天总共大概有1亿
- dw层 统一数仓层
  - dwd 明细数据层
  - dws 轻度聚合层
- dim层；维表层
- tdm：标签层
  - 不同业务中id的打通，是打标签的前提
- ads：数据应用层
  - 一般会放在ES，MYSQL，Redis等系统供线上系统使用，也可以放在Hive中供数据分析和数据挖掘使用，或者使用一下其他的大数据工具进行存储和使用

# 拉链表
- 定义：记录历史。记录一个事物从开始，一直到当前状态的所有变化的信息
- 场景
  - 表的行数量很多，约为10W，每行大于50个字段
  - 表中部分字段会被update,如用户的联系方式，产品的描述信息，订单的状态
  - 需要查看某个时间段的快照信息，如某一个订单再某个时间点的状态
  - 表中记录的变化的比例和频率不是很大，如10亿中有200W
- 实现
  - 以天为粒度，新建历史表
  - 获取每天的变动表：找到新的一天里变动和新增的
  - 将变化写入拉链表
- 5Gmme信令数据
  - 一个小时数据量为11.2亿条数据，用到5个字段，以50字节计算，30天有数据40TB数据，一天有1.34TB数据
  - 数据变化的比例很大，频率也很快
  - 对最新的用户状态没有那么关注，关注的是过程内的状态停留时间
  - 月粒度报错
    - spark 报错 IO excption  broken pipe
    - 猜测是内存资源不够
  - 方案
    - 历史拉链表+新的增量数据
      - 并不合适，因为update的比例可能很大，而且频率很快
    - 去掉null值，直接用前面的值
      - 有非null值的数目约为1/30
    - 不用排序，减少row——number
    - 大概是70%的内存
  - 问题
    - spark-sql orc文件异常
      - 查看hdfs,文件没有后缀
- 阿里巴巴-大数据实践之路
  - 缓慢变化维度——新增维度行——相对于快照维表的极限存储
  - 面对分区数量过多的问题，分月做，每个月初开始重新计算
- B站的思路
  - 场景
    - 日志型数据，又分为客户端日志和服务端日志，但无论哪类日志，一般来说均属于增量类、静态类数据，一旦产生即不会对数据本身进行再次变更
    - 业务型数据，主要来源于业务数据库中的生产数据，即传统的会进行 DDL、DML 等操作的数据，会频繁的进行增删改查。在数据仓库使用时，需要计算出最新状态，供下游使用
  - 全量分区表
    - 每天算出昨天的全量数据-相当于数据快照表
      - 存储浪费，数据存在丢失，重复存储，要定期删除
    - T-2的全量数据合并上T-1的增量数据，用离线链路，基于主键对更新时间分组排序，获取新的全量数据
      - 时效低，性能高，吞吐量大
    - 数据湖hudi,以离线模式批量从数据库中拉取全量数据，初始化到 Hudi 表中；订阅数据库的增量数据，增量更新到 Hudi 表中。数据以分钟级的延迟和数据库保持完全一致
      - 时效高、性能中、吞吐中
      - 经过基准性能测试，日新增、变更低于 1000 万条的数据，使用 Hudi+Flink CDC 可以较好的实现数据的合并，生产出数据的准实时数据
  - 拉链表
    - 通过记录历史所有数据的状态和数据的生命周期，保留所有的数据快照
    - T-2的拉链表数据+T-1的增量数据，获得最新的拉链数据
      - 将拉链表中变化的end_time做修改，写入增量的变化数据
      