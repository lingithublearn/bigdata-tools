# 数据抽取/采集
- dataX
  - 
- sqoop
  - 工具：本质就是迁移数据， 迁移的方式：就是把sqoop的迁移命令转换成MR程序
  - 功能
    - 导入数据：MySQL，Oracle 导入数据到 Hadoop 的 HDFS、HIVE、HBASE 等数据存储系统
    - 导出数据：从 Hadoop 的文件系统中导出数据到关系数据库 mysql 等 Sqoop 的本质还是一个命令行工具，和 HDFS，Hive 相比，并没有什么高深的理论
  - 工作机制
    - 将导入或导出命令翻译成 MapReduce 程序来实现 在翻译出的 MapReduce 中主要是对 InputFormat 和 OutputFormat 进行定制
  - 安装
    - sqoop就是一个工具， 只需要在一个节点上进行安装即可 http://mirrors.hust.edu.cn/apache/
    - ` tar -zxvf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz -C apps/`
    - 进入到 conf 文件夹，找到 sqoop-env-template.sh，修改其名称为 sqoop-env.sh cd conf
    - 修改 sqoop-env.sh
    - 加入 mysql 驱动包到 sqoop1.4.6/lib 目录下
    - 配置系统环境变量
    - 验证安装是否成功
  - 基本命令
    - sqoop help [import]
    - 执行sql,读，show,create
      - sqoop list-databases \
      - connect jdbc:mysql://hadoop1:3306/ \
      - username root \
      - password root
    - 数据导入
      - 从RDBMS导入到HDFS中
        - sqoop import (generic-args) (import-args)
        - --connect <jdbc-uri> jdbc 连接地址
          --connection-manager <class-name> 连接管理者
          --driver <class-name> 驱动类
          --hadoop-mapred-home <dir> $HADOOP_MAPRED_HOME
          --help help 信息
          -P 从命令行输入密码
          --password <password> 密码
          --username <username> 账号
          --verbose 打印流程信息
          --connection-param-file <filename> 可选参数
          --table xxx
        - 指定分隔符和导入路径
          - --target-dir /user/hadoop11/my_help_keyword1  \
          - --fields-terminated-by '\t'  \
        - 带where条件
          - --where "name='STRING' " \
        - 查询指定列
          - --columns "name" \
        - 指定自定义查询SQL
          - --query 'select help_keyword_id,name from mysql.help_keyword where $CONDITIONS and name = "STRING"' \
          - 引号问题，要么外层使用单引号，内层使用双引号，$CONDITIONS的$符号不用转义， 要么外层使用双引号，那么内层使用单引号，然后$CONDITIONS的$符号需要转义
          - 自定义的SQL语句中必须带有WHERE \$CONDITIONS
      - 把MySQL数据库中的表数据导入到Hive中
        - Sqoop 导入关系型数据到 hive 的过程是先导入到 hdfs，然后再 load 进入 hive
        - 普通导入：数据存储在默认的default hive库中，表名就是对应的mysql的表名：
          - --hive-import \
        - 指定行分隔符和列分隔符，指定hive-import，指定覆盖导入，指定自动创建hive表，指定表名，指定删除中间结果数据目录
          - --fields-terminated-by "\t"  \
            --lines-terminated-by "\n"  \
          - --hive-overwrite  \
            --create-hive-table  \
            --delete-target-dir \
            --hive-database  mydb_test \
            --hive-table new_help_keyword
          - --hive-table  mydb_test.new_help_keyword  \
        - sqoop会自动给创建hive的表。 但是不会自动创建不存在的库
        - 增量导入
          - --incremental  append  \
      - 把MySQL数据库中的表数据导入到hbase
        - --hbase-table new_help_keyword \
          --column-family person \
          --hbase-row-key help_keyword_id